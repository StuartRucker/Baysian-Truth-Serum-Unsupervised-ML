{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "network2_n_random_independent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1DIA-UqMu5-",
        "colab_type": "text"
      },
      "source": [
        "# N Random Independent\n",
        "This code tests how effectively the network keeps the information of N input nodes that occur with random frequency\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTY52NButZaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# tf.enable_eager_execution()\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "data_size = 300\n",
        "\n",
        "x_train = x_train[0:data_size]\n",
        "y_train = y_train[0:data_size]\n",
        "USING_MNIST = False\n",
        "x_train = []\n",
        "\n",
        "for i in range(data_size):\n",
        "  x_train.append([0 if .5 < random.random() else 1 for i in range(4)])\n",
        "      \n",
        "      \n",
        "#   x = round(math.sqrt(random.randint(0,255)))\n",
        "#   x_train.append([(x//8)%2,(x//4)%2,(x//2)%2,x%2])\n",
        "  \n",
        "  \n",
        "#   x_train.append([0 if x != i else 1 for i in range(8)])\n",
        "# for x in range(8):\n",
        "#   x_train.append([0 if x != i else 1 for i in range(8)])\n",
        "\n",
        "#   r = random.random()   \n",
        "#   if r < .3333:\n",
        "#     x_train.append([1,1,1])\n",
        "#   elif r < .666:\n",
        "#     x_train.append([1,1,0])\n",
        "#   else:\n",
        "#     x_train.append([0,1,1])\n",
        "x_train = np.array(x_train)\n",
        "\n",
        "s = tf.dtypes.cast(tf.constant(x_train),dtype=tf.float32)\n",
        "s = tf.reshape(s,[data_size,-1])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN3HPx8jibhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 3\n",
        "K = .5\n",
        "L = .2\n",
        "MU = 2\n",
        "\n",
        "s_size = s.shape[1]\n",
        "\n",
        "#creating an array of the permutations to aid in later computation of H(Y^0...Y^N)\n",
        "def get_options():\n",
        "  bin_options = list(itertools.product([0,1], repeat=N+1))\n",
        "  options = []\n",
        "  for row_index, row in enumerate(bin_options):\n",
        "    row_building = []\n",
        "    for index,val in enumerate(row):\n",
        "      row_building.append(index*2+val)\n",
        "    options.append(row_building)\n",
        "  return options\n",
        "\n",
        "options = get_options()\n",
        "\n",
        "#weights\n",
        "x = tf.Variable(tf.random_normal(shape=[int(s.shape[1]),N+1], stddev=0.1))\n",
        "B = tf.Variable(tf.random_normal(shape=[N+1], stddev=0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTH0M2YPmmM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#s: list of flattened images\n",
        "#returns: num_images by N vector of node probabilities for each image\n",
        "def compute_nodes(s):\n",
        "  x_clip = tf.clip_by_value(x,-8.0,8.0)\n",
        "  B_clip = tf.clip_by_value(B,-8.0,8.0)\n",
        "  layer = tf.matmul(s,x_clip)+B_clip\n",
        "  return tf.clip_by_value(tf.nn.sigmoid(layer),.01,.99)\n",
        "\n",
        "\n",
        "\n",
        "def compute_Hs(computed_nodes):\n",
        "  one_over_num_samples = 1/tf.dtypes.cast(computed_nodes.shape[0],dtype=tf.float32)\n",
        "  return -tf.math.log(one_over_num_samples)/math.log(2)\n",
        "  \n",
        "\n",
        "#p(y^k)\n",
        "def compute_pyk(computed_nodes):\n",
        "   return tf.math.reduce_mean(computed_nodes,axis=0)#CHECKED\n",
        "  \n",
        "def compute_Hs_y(computed_nodes):\n",
        "  num_samples = tf.dtypes.cast(computed_nodes.shape[0],dtype=tf.float32)\n",
        "  prob_y_and_s = (1./num_samples)*computed_nodes\n",
        "  prob_y_and_not_s = (1./num_samples)*(1-computed_nodes)\n",
        "  logedvals = prob_y_and_s*tf.math.log(prob_y_and_s)/math.log(2) + prob_y_and_not_s*tf.math.log(prob_y_and_not_s)/math.log(2)\n",
        "  return -tf.math.reduce_sum(logedvals,axis=0)\n",
        "\n",
        "#H(Y^k)\n",
        "#kth elemenent of returned value = H(Y^k)\n",
        "def compute_Hy_k(computed_nodes):\n",
        "  pyk = compute_pyk(computed_nodes)\n",
        "  logednodes_1 = tf.math.log(pyk)/math.log(2)\n",
        "  logednodes_2 = tf.math.log(1-pyk)/math.log(2)\n",
        "  \n",
        "  return -logednodes_1*pyk - logednodes_2*(1-pyk) #CHECKED\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#H(Y^0,...,Y^N)\n",
        "def compute_Hy(computed_nodes):\n",
        "  tf_options = tf.constant(options, dtype=tf.float32)\n",
        "  computed_nodes_both = [computed_nodes,1-computed_nodes]\n",
        "  \n",
        "  def process_image(row):\n",
        "    odds_both = [row,1-row]\n",
        "    def fnc(y):\n",
        "      def inner_func(x):\n",
        "        x = tf.dtypes.cast(x,dtype=tf.int32)\n",
        "        return tf.gather(tf.gather(odds_both,x%2),x//2)\n",
        "      return tf.map_fn(inner_func, y)\n",
        "    '''\n",
        "      vals is 2^(N+1) by N, where the [i][j] entry is probability that\n",
        "      in the ith permutation, say 0101,\n",
        "      (y^0=0, y^1=1, y^2=0, y^3=1)\n",
        "    '''\n",
        "    vals = tf.map_fn(fnc,tf_options)\n",
        "\n",
        "    reduced = tf.math.reduce_prod(vals,axis=1)\n",
        "\n",
        "    return reduced\n",
        "  \n",
        "  #p(y^0,y^1,...) length 2^n+1\n",
        "  pys = tf.math.reduce_mean(tf.map_fn(process_image,computed_nodes),axis=0)\n",
        "  return - tf.math.reduce_sum(pys*tf.math.log(pys)/math.log(2)) #Checked\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "#I(S:Y^k)\n",
        "#output[s][k] is mutual information between image s and node k\n",
        "def compute_Is_yk(computed_nodes):\n",
        "  pyk = compute_pyk(computed_nodes)\n",
        "  num_samples = tf.dtypes.cast(computed_nodes.shape[0],dtype=tf.float32)\n",
        "  \n",
        "  #yk=1\n",
        "  a = computed_nodes/pyk\n",
        "  output = computed_nodes/num_samples * tf.math.log(a)/math.log(2)\n",
        "  #yk=2\n",
        "  b = (1-computed_nodes)/(1-pyk)\n",
        "  output += (1-computed_nodes)/num_samples * tf.math.log(b)/math.log(2)\n",
        "  return output  #CHECKED\n",
        "\n",
        "\n",
        "\n",
        "#computer H(Y^i,Y^j)\n",
        "def compute_H_2(computed_nodes):\n",
        "\n",
        "  \n",
        "\n",
        "  def sub_compute(computed_nodes_1, computed_nodes_2):\n",
        "    def top(x):\n",
        "      return tf.reshape(tf.tile(x,[x.shape[0]]),[x.shape[0],x.shape[0]])\n",
        "    def bot(x):\n",
        "      return tf.transpose(tf.reshape(tf.tile(x,[x.shape[0]]),[x.shape[0],x.shape[0]]))\n",
        "    pairwise1 = tf.map_fn(bot,computed_nodes_1)\n",
        "    pairwise2 = tf.map_fn(top,computed_nodes_2)\n",
        "    prob_a_b = tf.math.reduce_mean(pairwise1*pairwise2,axis=0) #reduce mean across sample size\n",
        "#     print(prob_a_b[0][1]*math.log(prob_a_b[0][1])/math.log(2))\n",
        "#     print(\"\\nprob a b:\\n{}\\n\".format(prob_a_b))\n",
        "    return prob_a_b*tf.math.log(prob_a_b)/math.log(2)\n",
        "\n",
        "\n",
        "  info = sub_compute(computed_nodes, computed_nodes)+\\\n",
        "          sub_compute(1-computed_nodes, computed_nodes)+\\\n",
        "          sub_compute(computed_nodes, 1-computed_nodes)+\\\n",
        "          sub_compute(1-computed_nodes, 1-computed_nodes)\n",
        "  return -info*(1-tf.eye(N+1,N+1))\n",
        "\n",
        "#create NXN matrix  where [i][j]\n",
        "#is the mutual information between Y^i and Y^j\n",
        "def compute_I(computed_nodes):\n",
        "\n",
        "  \n",
        "\n",
        "  def sub_compute(computed_nodes_1, computed_nodes_2):\n",
        "    def top(x):\n",
        "      return tf.reshape(tf.tile(x,[x.shape[0]]),[x.shape[0],x.shape[0]])\n",
        "    def bot(x):\n",
        "      return tf.transpose(tf.reshape(tf.tile(x,[x.shape[0]]),[x.shape[0],x.shape[0]]))\n",
        "    pairwise1 = tf.map_fn(bot,computed_nodes_1)\n",
        "    pairwise2 = tf.map_fn(top,computed_nodes_2)\n",
        "    prob_a_b = tf.math.reduce_mean(pairwise1*pairwise2,axis=0) #reduce mean across sample size\n",
        "\n",
        "    \n",
        "    prob_a = bot(tf.math.reduce_mean(computed_nodes_1,0))\n",
        "    prob_b = top(tf.math.reduce_mean(computed_nodes_2,0))\n",
        "\n",
        "  \n",
        "    \n",
        "#     print(prob_a*prob_b)\n",
        "    return prob_a_b*tf.math.log(prob_a_b/(prob_a*prob_b))/math.log(2)\n",
        "\n",
        "\n",
        "  info = sub_compute(computed_nodes, computed_nodes)#+\\\n",
        "#           sub_compute(1-computed_nodes, computed_nodes)+\\\n",
        "#           sub_compute(computed_nodes, 1-computed_nodes)+\\\n",
        "#           sub_compute(1-computed_nodes, 1-computed_nodes)\n",
        "#   info = sub_compute(1-computed_nodes, computed_nodes)\n",
        "  return info*(1-tf.eye(N+1,N+1))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "#returns num_images by N array, where\n",
        "#[i][j] is the utility of node j with respect to image i\n",
        "def compute_utility(computed_nodes,image_outcome_info):\n",
        "  \n",
        "  first_term = MU*image_outcome_info #num_images by N vectir\n",
        "  tmp = compute_I(computed_nodes)\n",
        "\n",
        "  second_term = -(K-L)/N*(tf.reduce_sum(tmp,axis=0))\n",
        "  third_term = -(MU-K)*compute_Hy_k(computed_nodes) #vector length N\n",
        "  fourth_term = -L/N*tf.math.reduce_sum(compute_Hy(computed_nodes)) #number\n",
        "  \n",
        "#   print(\"\\nfirst term:\\n{}\\n\".format(first_term))\n",
        "#   print(\"\\nsecond term:\\n{}\\n\".format(second_term))\n",
        "#   print(\"\\nthird term:\\n{}\\n\".format(third_term))\n",
        "#   print(\"\\nfourth term:\\n{}\\n\".format(fourth_term))\n",
        "  \n",
        "  return first_term+second_term+third_term+fourth_term\n",
        "\n",
        "# def compute_total_info(computed_nodes, image_outcome\n",
        "\n",
        "\n",
        "def compute_information(computed_nodes):\n",
        "  term1 = (N+1)*compute_Hs(computed_nodes)\n",
        "  print(term1)\n",
        "#   print(\"term1:\\n{}\".format(term1))\n",
        "  term2 = -tf.reduce_sum(compute_Hs_y(computed_nodes))\n",
        "#   print(\"term2:\\n{}\".format(compute_Hs_y(computed_nodes)))\n",
        "  term3 = compute_Hy(computed_nodes)\n",
        "#   print(\"term3:\\n{}\".format(term3))\n",
        "  return term1+term2+term3\n",
        "\n",
        "def compute_utility_2(computed_nodes, mu, lamb, kappa):\n",
        "  term1 = mu*(compute_Hs(computed_nodes)-compute_Hs_y(computed_nodes))\n",
        "  \n",
        "  hyk = compute_Hy_k(computed_nodes)\n",
        "  term2 = lamb*N*hyk\n",
        "  \n",
        "  term3 = -kappa*(tf.reduce_sum(hyk))-hyk\n",
        "  \n",
        "  term4 = (lamb-kappa)*tf.reduce_sum(compute_H_2(computed_nodes),axis=0)\n",
        "#   print(\"reduced sum:\")\n",
        "#   print(compute_H_2(computed_nodes))\n",
        "\n",
        "                 \n",
        "#   print(\"trem4\")\n",
        "#   print(term4)\n",
        "  \n",
        "  return term1+term2+term3+term4\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jd76SAJB4No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_x_numb(x):\n",
        "  return int(8*float(x[0])+4*float(x[1])+2*float(x[2])+float(x[3]))\n",
        "def get_output(x):\n",
        "#   print(type(x))\n",
        "  output2 = map(lambda y:str(int(round(float(y)))),x)\n",
        "  return str(\"\".join(output2))\n",
        "def get_counts(key_list):\n",
        "    countdict = {}\n",
        "    for outcome in key_list:\n",
        "      if outcome not in countdict:\n",
        "        countdict[outcome] = 1\n",
        "      else:\n",
        "        countdict[outcome] += 1\n",
        "    return countdict\n",
        "\n",
        "def get_info(output):\n",
        "  \n",
        "  x_train_reshaped = x_train\n",
        "  if USING_MNIST:\n",
        "    x_train_reshaped = x_train.reshape(data_size,784)\n",
        "\n",
        "  outcomes_as_keys = list(map( get_output,output))\n",
        "  inputs_as_keys = list(map(get_output,x_train_reshaped))\n",
        "  \n",
        "  count_dict_outcome = get_counts(outcomes_as_keys)\n",
        "  count_dict_input = get_counts(inputs_as_keys)\n",
        "  \n",
        "  input_output = {}\n",
        "  for i in range(len(inputs_as_keys)):\n",
        "    input_output[inputs_as_keys[i]] = outcomes_as_keys[i]\n",
        "  \n",
        "#   print(odds_image)\n",
        "\n",
        "\n",
        "  \n",
        "  mutual_info = 0\n",
        "  number_samples = float(len(output))\n",
        "  #a\n",
        "  for input_str, input_odds in count_dict_input.items():\n",
        "    output_str = input_output[input_str]\n",
        "#     print(output_str + \" \" + input_str)\n",
        "    output_odds= count_dict_outcome[output_str]\n",
        "#     print(\"{} {}\".format(input_odds, output_odds))\n",
        "    mutual_info += input_odds/number_samples * math.log(1/(output_odds/number_samples))/math.log(2)\n",
        "    \n",
        "  \n",
        "  return mutual_info\n",
        "# print(get_info(output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iqnYgTx1Vew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_information_no_tf(computed_nodes, mu, lamb, kappa):\n",
        "  computed_nodes_tf = computed_nodes\n",
        "  \n",
        "  computed_nodes = list(computed_nodes)\n",
        "  computed_nodes_np = np.array(computed_nodes)\n",
        "  \n",
        "\n",
        "  num_images = float(len(computed_nodes))\n",
        "  \n",
        "  answer = [0]*len(computed_nodes[0])\n",
        "\n",
        "  for row in computed_nodes:\n",
        "    for node_index, val in enumerate(row):\n",
        "\n",
        "      answer[node_index] += float(mu*(1./num_images)*val*math.log(val)/math.log(2))\n",
        "      val2 = 1-val\n",
        "      answer[node_index] += float(mu*(1./num_images)*val2*math.log(val2)/math.log(2))\n",
        "\n",
        "\n",
        " \n",
        "  def get_conditionals(computed_nodes1,computed_nodes2):\n",
        "    pyk = compute_pyk(computed_nodes2)\n",
        "    conditional_probabilities = [[0 for i in range(N+1)] for k in range(N+1)]\n",
        "    for i in range(N+1):\n",
        "        for k in range(N+1):\n",
        "          if i == k:\n",
        "            continue\n",
        "          sumer = 0.\n",
        "          count = 0.\n",
        "          for im in range(len(computed_nodes)):\n",
        "            sumer += computed_nodes1[im][i]*computed_nodes2[im][k]\n",
        "            count += 1.\n",
        "          conditional_probabilities[i][k] = float((sumer/count)/pyk[k])\n",
        "    return np.array(conditional_probabilities)\n",
        "  \n",
        "  \n",
        "\n",
        "  conditional_probabilities = [get_conditionals(computed_nodes_np,computed_nodes_np), get_conditionals(1-computed_nodes_np,computed_nodes_np), \n",
        "                               get_conditionals(computed_nodes_np,1-computed_nodes_np), get_conditionals(1-computed_nodes_np,1-computed_nodes_np)]\n",
        "\n",
        "  \n",
        "  \n",
        "  print_dictionairy = {0:\"p(s{},y^{}=1,y^{}=1)\",1:\"p(s{},y^{}=2,y^{}=1)\",2:\"p(s{},y^{}=1,y^{}=2)\",3:\"p(s{},y^{}=2,y^{}=2)\"}\n",
        "  print_dictionairy_conditional = {0:\"p(y^{}=1 | y^{}=1)\",1:\"p(y^{}=2 | y^{}=1)\",2:\"p(y^{}=1 | y^{}=2)\",3:\"p(y^{}=2 | y^{}=2)\"}\n",
        "\n",
        "  for i_index, image in enumerate(computed_nodes):\n",
        "    for j, val_j_original in enumerate(image):\n",
        "      for k, val_k_original in enumerate(image):\n",
        "        if j == k:\n",
        "          continue\n",
        "        for value_index in range(4):\n",
        "          val_j = val_j_original\n",
        "          if value_index == 1 or value_index == 3:\n",
        "            val_j = 1-val_j_original\n",
        "          val_k = val_k_original\n",
        "          if value_index == 2 or value_index == 3:\n",
        "            val_k = 1-val_k_original\n",
        "\n",
        "          \n",
        "          addme =  float(lamb*(1./num_images)*val_j*val_k)*math.log(conditional_probabilities[value_index][j][k])/math.log(2)\n",
        "#           if k == 0:\n",
        "#             print(print_dictionairy[value_index].format(i_index,j,k) + \"* log(\" + print_dictionairy_conditional[value_index].format(j,k) + \\\n",
        "#                   \") = \" + str(float((1./num_images)*val_j*val_k)) + \" * log(\" + str(conditional_probabilities[value_index][j][k]) + \") = \" + str(addme))\n",
        "          \n",
        "          answer[k] += addme\n",
        " \n",
        "\n",
        "  for i_index, image in enumerate(computed_nodes):\n",
        "    for j, val_j_original in enumerate(image):\n",
        "      for k, val_k_original in enumerate(image):\n",
        "        if j == k:\n",
        "          continue\n",
        "        for value_index in range(4):\n",
        "          val_j = val_j_original\n",
        "          if value_index == 1 or value_index == 3:\n",
        "            val_j = 1-val_j_original\n",
        "          val_k = val_k_original\n",
        "          if value_index == 2 or value_index == 3:\n",
        "            val_k = 1-val_k_original\n",
        "          \n",
        "          answer[k] -= float(kappa*(1./num_images)*val_j*val_k)*math.log(conditional_probabilities[value_index][k][j])/math.log(2)\n",
        "        \n",
        "  return answer\n",
        "\n",
        "\n",
        "# print(compute_Hs(computed_nodes))\n",
        "# print(compute_Hs_y(computed_nodes))\n",
        "# print(compute_Hy_k(computed_nodes))\n",
        "# print(compute_H_2(computed_nodes))\n",
        "# print(compute_Hy(computed_nodes))\n",
        "\n",
        "# print(\"\\nH(s):\\n{}\".format(compute_Hs(computed_nodes)))\n",
        "# print(\"H(s,y^k):\\n{}\\n\".format(compute_Hs_y(computed_nodes)))\n",
        "# print(\"Real\")\n",
        "# print(get_information_no_tf(computed_nodes, 1, 2, 1))\n",
        "# print(\"tf\")\n",
        "# computed_nodes = tf.constant([[0.75, 0.25, 0.5],[0.1, 0.9, 0.5]])\n",
        "# computed_nodes2 = tf.constant([[0.99, 0.01, 0.5],[0.01, 0.99, 0.5]])\n",
        "# computed_nodes3 = tf.constant([[1, 0, 0.01],[0.01, 0.99, 0.99]])\n",
        "\n",
        "# print(compute_utility_2(computed_nodes,3,1,2))\n",
        "# print(compute_utility_2(computed_nodes2,3,1,2))\n",
        "# print(compute_utility_2(computed_nodes3,3,1,2))\n",
        "# print(N*compute_Hy_k(computed_nodes))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFSrbpYrj7I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dotheprint():\n",
        "  output = output_checkpoint\n",
        "  get_info(output)\n",
        "\n",
        "  numbers_to_output = {}\n",
        "  for i in range(len(x_train)):\n",
        "    if USING_MNIST:\n",
        "      num = y_train[i]\n",
        "    else:\n",
        "      num = x_train[i][0]*8+x_train[i][1]*4+x_train[i][2]*2+x_train[i][3]\n",
        "  #     print(num)\n",
        "\n",
        "    o = list(map(lambda x: int(x),list(get_output(output[i]))))\n",
        "    o = o[0]*8+o[1]*4+o[2]*2+o[3]\n",
        "\n",
        "    num,o=o,num\n",
        "  #   print(o)\n",
        "  #   print(\"{}->{}\".format(num,output))\n",
        "    s = numbers_to_output.get(num,[])\n",
        "    s.append(o)\n",
        "    numbers_to_output[num] = s\n",
        "  for i in range(16):\n",
        "    if i in numbers_to_output:\n",
        "      print(\"{} -> {}\".format(i,set(numbers_to_output[i])))\n",
        "  #     print(i)\n",
        "  #     print(set(numbers_to_output[i]))\n",
        "\n",
        "  if USING_MNIST:\n",
        "    string_to_output = {'000':0,'001':1,'010':2,'011':3,'100':4,'101':5,'110':6,'111':7}\n",
        "    def get_output_count(num):\n",
        "      counts = [0]*8\n",
        "      for val in numbers_to_output[num]:\n",
        "        counts[string_to_output[val]] += 1\n",
        "      return counts\n",
        "    for n in range(10):\n",
        "      print(\", \".join(map(lambda t: str(t),get_output_count(n))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8blgt3SUost3",
        "colab_type": "code",
        "outputId": "c294b829-2f53-4fc3-f4e0-25d269ed7cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1764
        }
      },
      "source": [
        "iterations = 500\n",
        "\n",
        "output = None\n",
        "output_checkpoint = None\n",
        "\n",
        "computed_nodes = compute_nodes(s)\n",
        "image_outcome_info = compute_Is_yk(computed_nodes)\n",
        "\n",
        "utility = compute_utility_2(computed_nodes,1,.4,.05)\n",
        "information = compute_information(computed_nodes)\n",
        "\n",
        "train_ops = []\n",
        "for i in range(N+1):\n",
        "  train_ops.append(tf.train.AdamOptimizer(1e-1).minimize(-utility[i]))\n",
        "train_op = tf.train.AdamOptimizer(1e-1).minimize(-tf.reduce_sum(utility))\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "last_information = 0\n",
        "\n",
        "print(\"sdsdsd\")\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op)\n",
        "\n",
        "\n",
        "    \n",
        "#     print(\"\\nresults:\\n{}\".format(sess.run(computed_nodes)))\n",
        "    for i in range(iterations):\n",
        "\n",
        "      if i%100==0:\n",
        "        output = sess.run(computed_nodes)\n",
        "        print(\"trial {}: utility = {}, information={}\".format(i,sess.run(utility),get_info(output)))\n",
        "        \n",
        "        if np.isfinite(output).all():\n",
        "          output_checkpoint = output\n",
        "          \n",
        "        information = get_info(output)\n",
        "#         if information == last_information:\n",
        "#           x = random.randint(0,2)\n",
        "#           print(\"entering fixit mode: Node {} selected\".format(x+1))\n",
        "#           for k in range(100):\n",
        "#              sess.run(train_ops[x])\n",
        "#           information = get_info(output)\n",
        "#           print(\"ending, new info = {}\".format(information))\n",
        "          \n",
        "        last_information = information\n",
        "        dotheprint()\n",
        "        \n",
        "        \n",
        "      for node in range(N+1):\n",
        "        sess.run(train_ops[node])\n",
        "#       sess.run(train_op)\n",
        "      if i % 50 == 0 and not np.isfinite(output).all():\n",
        "        break\n",
        "    print(\"\\nimages:\\n{}\".format(sess.run(s)))\n",
        "    print(\"\\nweights:\\n{}\".format(sess.run(x)))\n",
        "    print(\"\\nbiases:\\n{}\".format(sess.run(B)))\n",
        "    print(\"\\nresults:\\n{}\".format(sess.run(computed_nodes)))\n",
        "    output = sess.run(computed_nodes)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"mul_48:0\", shape=(), dtype=float32)\n",
            "sdsdsd\n",
            "trial 0: utility = [1.1033205 1.0985601 1.099362  1.099509 ], information=2.292392513460869\n",
            "2 -> {4}\n",
            "4 -> {12, 14}\n",
            "6 -> {13, 15}\n",
            "7 -> {0, 1, 5, 8, 9}\n",
            "12 -> {6}\n",
            "15 -> {2, 3, 7, 10, 11}\n",
            "trial 100: utility = [1.824997  1.9671613 1.9657384 1.889208 ], information=3.967702482757111\n",
            "0 -> {4}\n",
            "1 -> {0}\n",
            "2 -> {5}\n",
            "3 -> {1}\n",
            "4 -> {12}\n",
            "5 -> {8}\n",
            "6 -> {13}\n",
            "7 -> {9}\n",
            "8 -> {6}\n",
            "9 -> {2}\n",
            "10 -> {7}\n",
            "11 -> {3}\n",
            "12 -> {14}\n",
            "13 -> {10}\n",
            "14 -> {15}\n",
            "15 -> {11}\n",
            "trial 200: utility = [1.8238158 1.9652148 1.9644103 1.9635416], information=3.967702482757111\n",
            "0 -> {4}\n",
            "1 -> {0}\n",
            "2 -> {5}\n",
            "3 -> {1}\n",
            "4 -> {12}\n",
            "5 -> {8}\n",
            "6 -> {13}\n",
            "7 -> {9}\n",
            "8 -> {6}\n",
            "9 -> {2}\n",
            "10 -> {7}\n",
            "11 -> {3}\n",
            "12 -> {14}\n",
            "13 -> {10}\n",
            "14 -> {15}\n",
            "15 -> {11}\n",
            "trial 300: utility = [1.8286523 1.9644886 1.9647084 1.9632758], information=3.967702482757111\n",
            "0 -> {4}\n",
            "1 -> {0}\n",
            "2 -> {5}\n",
            "3 -> {1}\n",
            "4 -> {12}\n",
            "5 -> {8}\n",
            "6 -> {13}\n",
            "7 -> {9}\n",
            "8 -> {6}\n",
            "9 -> {2}\n",
            "10 -> {7}\n",
            "11 -> {3}\n",
            "12 -> {14}\n",
            "13 -> {10}\n",
            "14 -> {15}\n",
            "15 -> {11}\n",
            "trial 400: utility = [1.827253  1.9635142 1.9649785 1.9629925], information=3.967702482757111\n",
            "0 -> {4}\n",
            "1 -> {0}\n",
            "2 -> {5}\n",
            "3 -> {1}\n",
            "4 -> {12}\n",
            "5 -> {8}\n",
            "6 -> {13}\n",
            "7 -> {9}\n",
            "8 -> {6}\n",
            "9 -> {2}\n",
            "10 -> {7}\n",
            "11 -> {3}\n",
            "12 -> {14}\n",
            "13 -> {10}\n",
            "14 -> {15}\n",
            "15 -> {11}\n",
            "\n",
            "images:\n",
            "[[0. 0. 1. 0.]\n",
            " [0. 1. 1. 1.]\n",
            " [1. 1. 1. 0.]\n",
            " ...\n",
            " [1. 1. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 1. 0.]]\n",
            "\n",
            "weights:\n",
            "[[-1.0112919   9.208375    0.05939025  0.5692398 ]\n",
            " [-1.1301295   0.3156122   0.1600968  -8.289615  ]\n",
            " [ 8.664928    0.7846658  -0.01355504 -0.12828581]\n",
            " [ 1.1017174   0.3388351   8.606657    0.10800834]]\n",
            "\n",
            "biases:\n",
            "[-2.0757644 -4.6388345 -4.115789   3.6745124]\n",
            "\n",
            "results:\n",
            "[[0.99       0.02075148 0.0158385  0.97197485]\n",
            " [0.99       0.0391762  0.9825491  0.01279578]\n",
            " [0.9777479  0.98858607 0.01964951 0.02014333]\n",
            " ...\n",
            " [0.04247373 0.9822875  0.98375666 0.02537623]\n",
            " [0.27407458 0.01338693 0.9798503  0.9777415 ]\n",
            " [0.99       0.02823484 0.01853749 0.01150075]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qnXH2821XMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLMhHdxhYVgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output = output_checkpoint\n",
        "# print(output)\n",
        "# print(get_info(output)) \n",
        "\n",
        "\n",
        "\n",
        "numbs = {}\n",
        "for a in range(2):\n",
        "  for b in range(2):\n",
        "    for c in range(2):\n",
        "      numbs[str(a)+str(b)+str(c)] = set()\n",
        "for i in range(len(output)):\n",
        "  key = get_output(output[i])\n",
        "  value = x_train[i][0]*8+x_train[i][1]*4+x_train[i][2]*2+x_train[i][3]\n",
        "#   value = np.argmax(x_train[i])\n",
        "#   if value == 15:\n",
        "#     print()\n",
        "#     print(output[i])\n",
        "#     print(x_train[i])\n",
        "  numbs[key].add(value)\n",
        "\n",
        "    \n",
        "print(numbs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uj-FYkRYr-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# |"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}