{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised MNIST COnvnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzGyKHMuNh7F",
        "colab_type": "text"
      },
      "source": [
        "# Unsupervised Convolutional MNIST Classification\n",
        "\n",
        "This code places our information maximizing network on top of of a convolutional network. The backpropogation of the gradients into the convolutional network will make it such that the convolutional network captures as much meaningful information about the digits as possible. This in turn groups the images of numbers by value without any ground truth data. Although the results do not compare to unsupervised benchmarks, two images of the same number value are grouped into the same group with >50% probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RzN_267Neen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "print(len(x_train))\n",
        "data_size = 1000\n",
        "x_train = x_train[0:data_size]\n",
        "y_train = y_train[0:data_size]\n",
        "USING_MNIST = True\n",
        "# x_train = []\n",
        "\n",
        "# for i in range(300):\n",
        "#   x = random.randint(0,7)\n",
        "# #   x_train.append([(x//8)%2,(x//4)%2,(x//2)%2,x%2])\n",
        "#   x_train.append([0 if x != i else 1 for i in range(8)])\n",
        "# for x in range(8):\n",
        "#   x_train.append([0 if x != i else 1 for i in range(8)])\n",
        "\n",
        "#   r = random.random()   \n",
        "#   if r < .3333:\n",
        "#     x_train.append([1,1,1])\n",
        "#   elif r < .666:\n",
        "#     x_train.append([1,1,0])\n",
        "#   else:\n",
        "#     x_train.append([0,1,1])\n",
        "# x_train = np.array(x_train)\n",
        "\n",
        "s = tf.dtypes.cast(tf.constant(x_train > 125),dtype=tf.float32)\n",
        "s = tf.reshape(s,[data_size,-1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN3HPx8jibhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 3\n",
        "K = .05\n",
        "L = .4\n",
        "MU = 1\n",
        "\n",
        "s_size = s.shape[1]\n",
        "\n",
        "#creating an array of the permutations to aid in later computation of H(Y^0...Y^N)\n",
        "def get_options():\n",
        "  bin_options = list(itertools.product([0,1], repeat=N+1))\n",
        "  options = []\n",
        "  for row_index, row in enumerate(bin_options):\n",
        "    row_building = []\n",
        "    for index,val in enumerate(row):\n",
        "      row_building.append(index*2+val)\n",
        "    options.append(row_building)\n",
        "  return options\n",
        "\n",
        "options = get_options()\n",
        "\n",
        "#weights\n",
        "# x = tf.Variable(tf.random_normal(shape=[int(s.shape[1]),N+1], stddev=0.1))\n",
        "# B = tf.Variable(tf.random_normal(shape=[N+1], stddev=0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTH0M2YPmmM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create the neural network\n",
        "def conv_net(x, n_classes, dropout, reuse, is_training):\n",
        "\n",
        "    # TF Estimator input is a dict, in case of multiple inputs\n",
        "\n",
        "\n",
        "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
        "    # Reshape to match picture format [Height x Width x Channel]\n",
        "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    # Convolution Layer with 32 filters and a kernel size of 5\n",
        "    conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
        "    # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
        "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
        "\n",
        "    # Convolution Layer with 64 filters and a kernel size of 3\n",
        "    conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
        "    # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
        "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
        "\n",
        "    # Flatten the data to a 1-D vector for the fully connected layer\n",
        "    fc1 = tf.contrib.layers.flatten(conv2)\n",
        "\n",
        "    # Fully connected layer (in tf contrib folder for now)\n",
        "    fc1 = tf.layers.dense(fc1, 1024)\n",
        "    # Apply Dropout (if is_training is False, dropout is not applied)\n",
        "    fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
        "\n",
        "    # Output layer, class prediction\n",
        "    out = tf.layers.dense(fc1, n_classes)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "#s: list of flattened images\n",
        "#returns: num_images by N vector of node probabilities for each image\n",
        "def compute_nodes(s):\n",
        "  output = conv_net(s,N+1,.25,False,True)\n",
        "#   layer = tf.matmul(s,x)+B\n",
        "  \n",
        "  output = tf.clip_by_value(tf.nn.sigmoid(output),-4,4)\n",
        "  return tf.clip_by_value(tf.nn.sigmoid(output),.01,.99)\n",
        "\n",
        "\n",
        "\n",
        "def compute_Hs(computed_nodes):\n",
        "  one_over_num_samples = 1/tf.dtypes.cast(computed_nodes.shape[0],dtype=tf.float32)\n",
        "  return -tf.math.log(one_over_num_samples)/math.log(2)\n",
        "  \n",
        "\n",
        "#p(y^k)\n",
        "def compute_pyk(computed_nodes):\n",
        "   return tf.math.reduce_mean(computed_nodes,axis=0)#CHECKED\n",
        "  \n",
        "def compute_Hs_y(computed_nodes):\n",
        "  num_samples = tf.dtypes.cast(computed_nodes.shape[0],dtype=tf.float32)\n",
        "  prob_y_and_s = (1./num_samples)*computed_nodes\n",
        "  prob_y_and_not_s = (1./num_samples)*(1-computed_nodes)\n",
        "  logedvals = prob_y_and_s*tf.math.log(prob_y_and_s)/math.log(2) + prob_y_and_not_s*tf.math.log(prob_y_and_not_s)/math.log(2)\n",
        "  return -tf.math.reduce_sum(logedvals,axis=0)\n",
        "\n",
        "#H(Y^k)\n",
        "#kth elemenent of returned value = H(Y^k)\n",
        "def compute_Hy_k(computed_nodes):\n",
        "  pyk = compute_pyk(computed_nodes)\n",
        "  logednodes_1 = tf.math.log(pyk)/math.log(2)\n",
        "  logednodes_2 = tf.math.log(1-pyk)/math.log(2)\n",
        "  \n",
        "  return -logednodes_1*pyk - logednodes_2*(1-pyk) #CHECKED\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#H(Y^0,...,Y^N)\n",
        "def compute_Hy(computed_nodes):\n",
        "  tf_options = tf.constant(options, dtype=tf.float32)\n",
        "  computed_nodes_both = [computed_nodes,1-computed_nodes]\n",
        "  \n",
        "  def process_image(row):\n",
        "    odds_both = [row,1-row]\n",
        "    def fnc(y):\n",
        "      def inner_func(x):\n",
        "        x = tf.dtypes.cast(x,dtype=tf.int32)\n",
        "        return tf.gather(tf.gather(odds_both,x%2),x//2)\n",
        "      return tf.map_fn(inner_func, y)\n",
        "    '''\n",
        "      vals is 2^(N+1) by N, where the [i][j] entry is probability that\n",
        "      in the ith permutation, say 0101,\n",
        "      (y^0=0, y^1=1, y^2=0, y^3=1)\n",
        "    '''\n",
        "    vals = tf.map_fn(fnc,tf_options)\n",
        "\n",
        "    reduced = tf.math.reduce_prod(vals,axis=1)\n",
        "\n",
        "    return reduced\n",
        "  \n",
        "  #p(y^0,y^1,...) length 2^n+1\n",
        "  pys = tf.math.reduce_mean(tf.map_fn(process_image,computed_nodes),axis=0)\n",
        "  return - tf.math.reduce_sum(pys*tf.math.log(pys)/math.log(2)) #Checked\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "#I(S:Y^k)\n",
        "#output[s][k] is mutual information between image s and node k\n",
        "def compute_Is_yk(computed_nodes):\n",
        "  pyk = compute_pyk(computed_nodes)\n",
        "  num_samples = tf.dtypes.cast(computed_nodes.shape[0],dtype=tf.float32)\n",
        "  \n",
        "  #yk=1\n",
        "  a = computed_nodes/pyk\n",
        "  output = computed_nodes/num_samples * tf.math.log(a)/math.log(2)\n",
        "  #yk=2\n",
        "  b = (1-computed_nodes)/(1-pyk)\n",
        "  output += (1-computed_nodes)/num_samples * tf.math.log(b)/math.log(2)\n",
        "  return output  #CHECKED\n",
        "\n",
        "\n",
        "\n",
        "#computer H(Y^i,Y^j)\n",
        "def compute_H_2(computed_nodes):\n",
        "\n",
        "  \n",
        "\n",
        "  def sub_compute(computed_nodes_1, computed_nodes_2):\n",
        "    def top(x):\n",
        "      return tf.reshape(tf.tile(x,[x.shape[0]]),[x.shape[0],x.shape[0]])\n",
        "    def bot(x):\n",
        "      return tf.transpose(tf.reshape(tf.tile(x,[x.shape[0]]),[x.shape[0],x.shape[0]]))\n",
        "    pairwise1 = tf.map_fn(bot,computed_nodes_1)\n",
        "    pairwise2 = tf.map_fn(top,computed_nodes_2)\n",
        "    prob_a_b = tf.math.reduce_mean(pairwise1*pairwise2,axis=0) #reduce mean across sample size\n",
        "#     print(prob_a_b[0][1]*math.log(prob_a_b[0][1])/math.log(2))\n",
        "#     print(\"\\nprob a b:\\n{}\\n\".format(prob_a_b))\n",
        "    return prob_a_b*tf.math.log(prob_a_b)/math.log(2)\n",
        "\n",
        "\n",
        "  info = sub_compute(computed_nodes, computed_nodes)+\\\n",
        "          sub_compute(1-computed_nodes, computed_nodes)+\\\n",
        "          sub_compute(computed_nodes, 1-computed_nodes)+\\\n",
        "          sub_compute(1-computed_nodes, 1-computed_nodes)\n",
        "  return -info*(1-tf.eye(N+1,N+1))\n",
        "\n",
        "#create NXN matrix  where [i][j]\n",
        "#is the mutual information between Y^i and Y^j\n",
        "def compute_I(computed_nodes):\n",
        "\n",
        "  \n",
        "\n",
        "  def sub_compute(computed_nodes_1, computed_nodes_2):\n",
        "    def top(x):\n",
        "      return tf.reshape(tf.tile(x,[x.shape[0]]),[x.shape[0],x.shape[0]])\n",
        "    def bot(x):\n",
        "      return tf.transpose(tf.reshape(tf.tile(x,[x.shape[0]]),[x.shape[0],x.shape[0]]))\n",
        "    pairwise1 = tf.map_fn(bot,computed_nodes_1)\n",
        "    pairwise2 = tf.map_fn(top,computed_nodes_2)\n",
        "    prob_a_b = tf.math.reduce_mean(pairwise1*pairwise2,axis=0) #reduce mean across sample size\n",
        "\n",
        "    \n",
        "    prob_a = bot(tf.math.reduce_mean(computed_nodes_1,0))\n",
        "    prob_b = top(tf.math.reduce_mean(computed_nodes_2,0))\n",
        "\n",
        "  \n",
        "    \n",
        "#     print(prob_a*prob_b)\n",
        "    return prob_a_b*tf.math.log(prob_a_b/(prob_a*prob_b))/math.log(2)\n",
        "\n",
        "\n",
        "  info = sub_compute(computed_nodes, computed_nodes)+\\\n",
        "          sub_compute(1-computed_nodes, computed_nodes)+\\\n",
        "          sub_compute(computed_nodes, 1-computed_nodes)+\\\n",
        "          sub_compute(1-computed_nodes, 1-computed_nodes)\n",
        "#   info = sub_compute(1-computed_nodes, computed_nodes)\n",
        "  return info*(1-tf.eye(N+1,N+1))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "#returns num_images by N array, where\n",
        "#[i][j] is the utility of node j with respect to image i\n",
        "def compute_utility(computed_nodes,image_outcome_info):\n",
        "  \n",
        "  first_term = MU*image_outcome_info #num_images by N vectir\n",
        "  tmp = compute_I(computed_nodes)\n",
        "\n",
        "  second_term = -(K-L)/N*(tf.reduce_sum(tmp,axis=0))\n",
        "  third_term = -(MU-K)*compute_Hy_k(computed_nodes) #vector length N\n",
        "  fourth_term = -L/N*tf.math.reduce_sum(compute_Hy(computed_nodes)) #number\n",
        "  \n",
        "#   print(\"\\nfirst term:\\n{}\\n\".format(first_term))\n",
        "#   print(\"\\nsecond term:\\n{}\\n\".format(second_term))\n",
        "#   print(\"\\nthird term:\\n{}\\n\".format(third_term))\n",
        "#   print(\"\\nfourth term:\\n{}\\n\".format(fourth_term))\n",
        "  \n",
        "  return first_term+second_term+third_term+fourth_term\n",
        "\n",
        "# def compute_total_info(computed_nodes, image_outcome\n",
        "\n",
        "\n",
        "def compute_information(computed_nodes):\n",
        "  term1 = (N+1)*compute_Hs(computed_nodes)\n",
        "  print(term1)\n",
        "#   print(\"term1:\\n{}\".format(term1))\n",
        "  term2 = -tf.reduce_sum(compute_Hs_y(computed_nodes))\n",
        "#   print(\"term2:\\n{}\".format(compute_Hs_y(computed_nodes)))\n",
        "  term3 = compute_Hy(computed_nodes)\n",
        "#   print(\"term3:\\n{}\".format(term3))\n",
        "  return term1+term2+term3\n",
        "\n",
        "def compute_utility_2(computed_nodes, mu, lamb, kappa):\n",
        "  term1 = mu*(compute_Hs(computed_nodes)-compute_Hs_y(computed_nodes))\n",
        "  hyk = compute_Hy_k(computed_nodes)\n",
        "  term2 = lamb*N*hyk\n",
        "  term3 = -kappa*(tf.reduce_sum(hyk))-hyk\n",
        "  term4 = (lamb-kappa)*tf.reduce_sum(compute_H_2(computed_nodes),axis=0)\n",
        "#   print(\"reduced sum:\")\n",
        "#   print(compute_H_2(computed_nodes))\n",
        "\n",
        "                 \n",
        "#   print(\"trem4\")\n",
        "#   print(term4)\n",
        "  \n",
        "  return term1+term2+term3+term4\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrARrdE1NdUJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEBoAcJC4hlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jd76SAJB4No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_x_numb(x):\n",
        "  return int(8*float(x[0])+4*float(x[1])+2*float(x[2])+float(x[3]))\n",
        "def get_output(x):\n",
        "#   print(type(x))\n",
        "  output2 = map(lambda y:str(int(round(float(y)))),x)\n",
        "  return str(\"\".join(output2))\n",
        "def get_counts(key_list):\n",
        "    countdict = {}\n",
        "    for outcome in key_list:\n",
        "      if outcome not in countdict:\n",
        "        countdict[outcome] = 1\n",
        "      else:\n",
        "        countdict[outcome] += 1\n",
        "    return countdict\n",
        "\n",
        "def get_info(output):\n",
        "\n",
        "  if USING_MNIST:\n",
        "    x_train_reshaped = x_train.reshape(data_size,784)\n",
        "  outcomes_as_keys = list(map( get_output,output))\n",
        "  inputs_as_keys = list(map(get_output,x_train_reshaped))\n",
        "  \n",
        "  count_dict_outcome = get_counts(outcomes_as_keys)\n",
        "  count_dict_input = get_counts(inputs_as_keys)\n",
        "  \n",
        "  input_output = {}\n",
        "  for i in range(len(inputs_as_keys)):\n",
        "    input_output[inputs_as_keys[i]] = outcomes_as_keys[i]\n",
        "  \n",
        "#   print(odds_image)\n",
        "\n",
        "\n",
        "  \n",
        "  mutual_info = 0\n",
        "  number_samples = float(len(output))\n",
        "  #a\n",
        "  for input_str, input_odds in count_dict_input.items():\n",
        "    output_str = input_output[input_str]\n",
        "    output_odds= count_dict_outcome[output_str]\n",
        "    mutual_info += input_odds/number_samples * math.log(1/(output_odds/number_samples))/math.log(2)\n",
        "    \n",
        "  \n",
        "  return mutual_info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iqnYgTx1Vew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_information_no_tf(computed_nodes, mu, lamb, kappa):\n",
        "  computed_nodes_tf = computed_nodes\n",
        "  \n",
        "  computed_nodes = list(computed_nodes)\n",
        "  computed_nodes_np = np.array(computed_nodes)\n",
        "  \n",
        "\n",
        "  num_images = float(len(computed_nodes))\n",
        "  \n",
        "  answer = [0]*len(computed_nodes[0])\n",
        "\n",
        "  for row in computed_nodes:\n",
        "    for node_index, val in enumerate(row):\n",
        "\n",
        "      answer[node_index] += float(mu*(1./num_images)*val*math.log(val)/math.log(2))\n",
        "      val2 = 1-val\n",
        "      answer[node_index] += float(mu*(1./num_images)*val2*math.log(val2)/math.log(2))\n",
        "\n",
        "\n",
        " \n",
        "  def get_conditionals(computed_nodes1,computed_nodes2):\n",
        "    pyk = compute_pyk(computed_nodes2)\n",
        "    conditional_probabilities = [[0 for i in range(N+1)] for k in range(N+1)]\n",
        "    for i in range(N+1):\n",
        "        for k in range(N+1):\n",
        "          if i == k:\n",
        "            continue\n",
        "          sumer = 0.\n",
        "          count = 0.\n",
        "          for im in range(len(computed_nodes)):\n",
        "            sumer += computed_nodes1[im][i]*computed_nodes2[im][k]\n",
        "            count += 1.\n",
        "          conditional_probabilities[i][k] = float((sumer/count)/pyk[k])\n",
        "    return np.array(conditional_probabilities)\n",
        "  \n",
        "  \n",
        "\n",
        "  conditional_probabilities = [get_conditionals(computed_nodes_np,computed_nodes_np), get_conditionals(1-computed_nodes_np,computed_nodes_np), \n",
        "                               get_conditionals(computed_nodes_np,1-computed_nodes_np), get_conditionals(1-computed_nodes_np,1-computed_nodes_np)]\n",
        "\n",
        "  \n",
        "  \n",
        "  print_dictionairy = {0:\"p(s{},y^{}=1,y^{}=1)\",1:\"p(s{},y^{}=2,y^{}=1)\",2:\"p(s{},y^{}=1,y^{}=2)\",3:\"p(s{},y^{}=2,y^{}=2)\"}\n",
        "  print_dictionairy_conditional = {0:\"p(y^{}=1 | y^{}=1)\",1:\"p(y^{}=2 | y^{}=1)\",2:\"p(y^{}=1 | y^{}=2)\",3:\"p(y^{}=2 | y^{}=2)\"}\n",
        "\n",
        "  for i_index, image in enumerate(computed_nodes):\n",
        "    for j, val_j_original in enumerate(image):\n",
        "      for k, val_k_original in enumerate(image):\n",
        "        if j == k:\n",
        "          continue\n",
        "        for value_index in range(4):\n",
        "          val_j = val_j_original\n",
        "          if value_index == 1 or value_index == 3:\n",
        "            val_j = 1-val_j_original\n",
        "          val_k = val_k_original\n",
        "          if value_index == 2 or value_index == 3:\n",
        "            val_k = 1-val_k_original\n",
        "\n",
        "          \n",
        "          addme =  float(lamb*(1./num_images)*val_j*val_k)*math.log(conditional_probabilities[value_index][j][k])/math.log(2)\n",
        "#           if k == 0:\n",
        "#             print(print_dictionairy[value_index].format(i_index,j,k) + \"* log(\" + print_dictionairy_conditional[value_index].format(j,k) + \\\n",
        "#                   \") = \" + str(float((1./num_images)*val_j*val_k)) + \" * log(\" + str(conditional_probabilities[value_index][j][k]) + \") = \" + str(addme))\n",
        "          \n",
        "          answer[k] += addme\n",
        " \n",
        "\n",
        "  for i_index, image in enumerate(computed_nodes):\n",
        "    for j, val_j_original in enumerate(image):\n",
        "      for k, val_k_original in enumerate(image):\n",
        "        if j == k:\n",
        "          continue\n",
        "        for value_index in range(4):\n",
        "          val_j = val_j_original\n",
        "          if value_index == 1 or value_index == 3:\n",
        "            val_j = 1-val_j_original\n",
        "          val_k = val_k_original\n",
        "          if value_index == 2 or value_index == 3:\n",
        "            val_k = 1-val_k_original\n",
        "          \n",
        "          answer[k] -= float(kappa*(1./num_images)*val_j*val_k)*math.log(conditional_probabilities[value_index][k][j])/math.log(2)\n",
        "        \n",
        "  return answer\n",
        "\n",
        "\n",
        "# print(compute_Hs(computed_nodes))\n",
        "# print(compute_Hs_y(computed_nodes))\n",
        "# print(compute_Hy_k(computed_nodes))\n",
        "# print(compute_H_2(computed_nodes))\n",
        "# print(compute_Hy(computed_nodes))\n",
        "\n",
        "# print(\"\\nH(s):\\n{}\".format(compute_Hs(computed_nodes)))\n",
        "# print(\"H(s,y^k):\\n{}\\n\".format(compute_Hs_y(computed_nodes)))\n",
        "# print(\"Real\")\n",
        "# print(get_information_no_tf(computed_nodes, 1, 2, 1))\n",
        "# print(\"tf\")\n",
        "# computed_nodes = tf.constant([[0.75, 0.25, 0.5],[0.1, 0.9, 0.5]])\n",
        "# computed_nodes2 = tf.constant([[0.99, 0.01, 0.5],[0.01, 0.99, 0.5]])\n",
        "# computed_nodes3 = tf.constant([[1, 0, 0.01],[0.01, 0.99, 0.99]])\n",
        "\n",
        "# print(compute_utility_2(computed_nodes,3,1,2))\n",
        "# print(compute_utility_2(computed_nodes2,3,1,2))\n",
        "# print(compute_utility_2(computed_nodes3,3,1,2))\n",
        "# print(N*compute_Hy_k(computed_nodes))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8blgt3SUost3",
        "colab_type": "code",
        "outputId": "26da3dde-b834-4f29-a406-905c88992e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        }
      },
      "source": [
        "iterations = 4000\n",
        "\n",
        "output = None\n",
        "output_checkpoint = None\n",
        "\n",
        "computed_nodes = compute_nodes(s)\n",
        "image_outcome_info = compute_Is_yk(computed_nodes)\n",
        "\n",
        "utility = compute_utility_2(computed_nodes,1,.4,.05)\n",
        "information = compute_information(computed_nodes)\n",
        "\n",
        "train_ops = []\n",
        "for i in range(N+1):\n",
        "  train_ops.append(tf.train.AdamOptimizer(1e-3).minimize(-utility[i]))\n",
        "train_op = tf.train.AdamOptimizer(1e-2).minimize(-tf.reduce_sum(utility))\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "last_information = 0\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op)\n",
        "\n",
        "#     print(\"\\nresults:\\n{}\".format(sess.run(computed_nodes)))\n",
        "    for i in range(iterations):\n",
        "\n",
        "      if i%2==0:\n",
        "        output = sess.run(computed_nodes)\n",
        "        print(\"trial {}: utility = {}, information={}\".format(i,sess.run(utility),get_info(output)))\n",
        "        print(sess.run(computed_nodes))\n",
        "        if np.isfinite(output).all():\n",
        "          output_checkpoint = output\n",
        "          \n",
        "        information = get_info(output)\n",
        "#         if information == last_information:\n",
        "#           x = random.randint(0,2)\n",
        "#           print(\"entering fixit mode: Node {} selected\".format(x+1))\n",
        "#           for k in range(100):\n",
        "#              sess.run(train_ops[x])\n",
        "#           information = get_info(output)\n",
        "#           print(\"ending, new info = {}\".format(information))\n",
        "          \n",
        "        last_information = information\n",
        "        \n",
        "        \n",
        "      for node in range(N+1):\n",
        "        sess.run(train_ops[node])\n",
        "#       sess.run(train_op)\n",
        "      if i % 50 == 0 and not np.isfinite(output).all():\n",
        "        break\n",
        "    print(\"\\nimages:\\n{}\".format(sess.run(s)))\n",
        "#     print(\"\\nweights:\\n{}\".format(sess.run(x)))\n",
        "#     print(\"\\nbiases:\\n{}\".format(sess.run(B)))\n",
        "    print(\"\\nresults:\\n{}\".format(sess.run(computed_nodes)))\n",
        "    output = sess.run(computed_nodes)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-5bff6169bb8f>:12: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-3-5bff6169bb8f>:14: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.max_pooling2d instead.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-3-5bff6169bb8f>:25: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-3-5bff6169bb8f>:27: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "tf.Tensor(39.863136, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a0a46b8ffaee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mtrain_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       raise RuntimeError(\n\u001b[0;32m--> 481\u001b[0;31m           \u001b[0;34m\"`loss` passed to Optimizer.compute_gradients should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m           \"be a function when eager execution is enabled.\")\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: `loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X1kxG9tICSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "0print(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qnXH2821XMG",
        "colab_type": "code",
        "outputId": "df19e4fd-088a-4782-92c3-bd2ff13665b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def dotheprint():\n",
        "  output = output_checkpoint\n",
        "  get_info(output)\n",
        "\n",
        "  numbers_to_output = {}\n",
        "  for i in range(len(x_train)):\n",
        "    if USING_MNIST:\n",
        "      num = y_train[i]\n",
        "    else:\n",
        "      num = x_train[i][0]*8+x_train[i][1]*4+x_train[i][2]*2+x_train[i][3]\n",
        "  #     print(num)\n",
        "\n",
        "    o = list(map(lambda x: int(x),list(get_output(output[i]))))\n",
        "    \n",
        "    o = 8*o[0]+4*o[1]+2*o[2]+o[3]\n",
        "#     print(o)\n",
        "#     print(o)\n",
        "    num,o=o,num\n",
        "  #   print(o)\n",
        "  #   print(\"{}->{}\".format(num,output))\n",
        "    s = numbers_to_output.get(num,[])\n",
        "    s.append(o)\n",
        "    numbers_to_output[num] = s\n",
        "  for i in range(16):\n",
        "    if i in numbers_to_output:\n",
        "      print(\"{} -> {}\".format(i,set(numbers_to_output[i])))\n",
        "  #     print(i)\n",
        "  #     print(set(numbers_to_output[i]))\n",
        "\n",
        "#   if USING_MNIST:\n",
        "#     string_to_output = {'000':0,'001':1,'010':2,'011':3,'100':4,'101':5,'110':6,'111':7}\n",
        "#     def get_output_count(num):\n",
        "#       counts = [0]*8\n",
        "#       for val in numbers_to_output[num]:\n",
        "#         counts[string_to_output[val]] += 1\n",
        "#       return counts\n",
        "#     for n in range(10):\n",
        "#       print(\", \".join(map(lambda t: str(t),get_output_count(n))))\n",
        "dotheprint()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 -> {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLMhHdxhYVgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output = output_checkpoint\n",
        "print(output)\n",
        "# print(get_info(output)) \n",
        "\n",
        "\n",
        "\n",
        "numbs = {}\n",
        "for a in range(2):\n",
        "  for b in range(2):\n",
        "    for c in range(2):\n",
        "      numbs[str(a)+str(b)+str(c)] = set()\n",
        "for i in range(len(output)):\n",
        "  key = get_output(output[i])\n",
        "\n",
        "  value = np.argmax(x_train[i])\n",
        "#   if value == 15:\n",
        "#     print()\n",
        "#     print(output[i])\n",
        "#     print(x_train[i])\n",
        "  numbs[key].add(value)\n",
        "\n",
        "    \n",
        "print(numbs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uj-FYkRYr-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# |"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwjBP547bSdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}